# COMP4300/8300 Parallel Systems Advection Notes, 2023

Stencil computations arise from applying *explicit methods* to the solution of Partial Differential Equations. Most large-scale scientific applications are based on solvers for such equations. A very commonly used component of such solvers will be the advection process, which models the process of *transport*, e.g. wind in an atmosphere simulation. In practice, the most important uses for advection solvers are for 3D phenomena. However, 2D solvers can still model some important problems, e.g. water surface wave propagation, and are considerably simpler to implement. When solved on a 2D regular Cartesian grid, advection uses a 9-point stencil (unlike the heat flow problem, which is a 5-point stencil). 

The provided test programs will simulate the advection (motion) of a sine wave across the unit square. An array `u` is set to the field values (i.e. water height) across the square accordingly. The process is iterated over a number of timesteps, and the solution will be the field values in `u` at that point. The boundary conditions are *wrap around*, that is field values at `x = 0` become those at `x = 1` (and conversely). This similarly occurs for the y-dimension. It is possible to compute an exact analytical solution to the advection problem. This can be used to calculate the discretization error in the solution.

The discretization error increases with time (the number of repetitions `r`) and decreases with increasing grid size `(M, N)`. Parallelization of the algorithm, and all other optimizations that we will perform, should produce a numerically identical solution, i.e. have exactly the same discretization error. In our context, this is a very useful property as an increase in the reported error, even a very small one, from a parallelized/optimized version indicates an algorithmic error. This could result from, for example, an error in handling the boundaries.

The boundary conditions are handled as follows. If the size of the field is `MxN`, the array `u` is size `(M+2)x(N+2)`, in order to store an extra row on the top and bottom, and an extra column to the left and right. These are used to store the boundary values (these are also known as *ghost cells*). That is, the corner elements of the halo are at indices *(0,0)*, *(0,N+1)*, *(M+1,N+1)*, *(M+1,0)*; whereas the corner elements of the interior field are at indices *(1,1)*, *(1,N)*, *(M,N)*, *(M,1)*. The elements of the boundary of the inner field are used to form the halo; these points are referred to as the *inner halo*. Due to the (outer) halo, all interior field elements can be updated in a uniform way. In a parallel implementation on a `P` by `Q` process grid, halos are also used to store the interior field elements of the neighbouring processes, for the same reason. Unlike the heat flow problem, the corner points for the halos are used in the update of the corner elements of the interior field. However, by using a 2-stage halo exchange (i.e. top-bottom then left-right), with the 2nd exchange of being of size `M+2` instead of `M`, the corner points can be exchanged implicitly.

